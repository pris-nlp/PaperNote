## 数据集
* 来自于论文[Personalization in Goal-Oriented Dialog](https://drive.google.com/open?id=1EcpoZFejVpRdfz6R289-SflhDG2siOvY) **NIPS2017** 

* [github link](https://github.com/chaitjo/personalized-dialog)

* 注意数据集可以通过[dropbox](https://www.dropbox.com/s/4i9u4y24pt3paba/personalized-dialog-dataset.tar.gz?dl=1)也可以通过[ParlAI](https://github.com/facebookresearch/ParlAI) ：数据集有两个full,small
> a full set with 6000/12000 dialogs each for training, development and testing; and a small set restricted to 1000 dialogs each for training, development and testing

**对话格式**：
共有full和small两个数据集（餐厅预订），区别只是含有的对话数量不同，都分为train/dev/test三种；每个数据集都包含5个任务，每个任务都对应着train/dev/test，但还包含一个额外的test，区别在于里面的对话含有train/dev里没有的实体。

例如：`personalized-dialog-task1-API-calls-trn.txt` `personalized-dialog-task1-API-calls-dev.txt` `personalized-dialog-task1-API-calls-tst.txt`  `personalized-dialog-task1-API-calls-tst-OOV.txt`

每个txt文件中对话的格式为：
```
1 user_attributes
ID user_utterance [tab] bot_utterances
...
```
每个对话都是以`1 user_attributes`开始（好像profile只有两个属性gender age,待确认），然后每一行是`ID user_utterance [tab] bot_utterances` （注意只有此处是tab，其余是空格），如果一个turn用户没有说话，用`<SILENCE>`代替。

用户profile只有两个属性：
| gender | age |
|--|--|
| male | young |
| male | middle-aged |
| male | elderly |
| female | young |
| female | middle-aged|
| female | elderly |
```
1 male elderly
2 hello	greetings sir what may i assist you with today
3 may i have a table in a moderate price range with italian food for eight	excellent sir i will start the request now
4 <SILENCE>	may i know where the restaurant should be located
5 bombay please	excellent sir please give me a moment to provide you with options
6 <SILENCE>	api_call italian bombay eight moderate
```

> The goal of the tasks is to predict the bot utterances, that can be sentences or API calls (sentences starting with the special token "api_call").

![demo](http://imglf6.nosdn0.126.net/img/bG1jbzEvdHVjVjNteXRHWHF4RHNFc3pvbU5LTVhhMTU5ZkFVa0lxWUNtam1Xb25MMEd3ZUZBPT0.png?imageView&thumbnail=500x0&quality=96&stripmeta=0)

**KB**：
两个数据集共用一个KB（`personalized-dialog-kb-all.txt`），每一行格式如下：`ID resto_name slot slot_value`；共有12个slot
```
1 resto_bangkok_cheap_cantonese_1stars_1 R_cuisine	cantonese
1 resto_bangkok_cheap_cantonese_1stars_1 R_location	bangkok
1 resto_bangkok_cheap_cantonese_1stars_1 R_price	cheap
1 resto_bangkok_cheap_cantonese_1stars_1 R_rating	1
1 resto_bangkok_cheap_cantonese_1stars_1 R_phone	resto_bangkok_cheap_cantonese_1stars_1_phone
1 resto_bangkok_cheap_cantonese_1stars_1 R_address	resto_bangkok_cheap_cantonese_1stars_1_address
1 resto_bangkok_cheap_cantonese_1stars_1 R_number	six
1 resto_bangkok_cheap_cantonese_1stars_1 R_type	veg
1 resto_bangkok_cheap_cantonese_1stars_1 R_speciality	hainanese_rice
1 resto_bangkok_cheap_cantonese_1stars_1 R_social_media	resto_bangkok_cheap_cantonese_1stars_1_social_media
1 resto_bangkok_cheap_cantonese_1stars_1 R_parking	resto_bangkok_cheap_cantonese_1stars_1_parking
1 resto_bangkok_cheap_cantonese_1stars_1 R_public_transport resto_bangkok_cheap_cantonese_1stars_1_public_transport
```

**Bot Response Candidate**：`personalized-dialog-candidates.txt`
简单的从整个数据集提取的回复，共43863条（很蠢的做法）

除此之外，还有一个`split-by-profile`数据集，按照不同的profile分隔（共有6种），每一个profile对应1000 dialogs for train/dev/test，作者认为这个可以用来测试模型多任务学习的能力。（作者认为的多任务学习是指针对于不同的profile建立不同的模型）

**Note：**
这个数据集也是通过规则生成，作者首先假定`location`,`cuisine`,  `price range`  and  `party size`  这四个slot必须先询问得知，只有这四个slot的值确定之后才开始API_call，也即查询KB。

> the  personalization  of  the  bot’s  responses  are  handcrafted  to  be  extremely  simplistic  in comparison  to  real  life  situations.

## Tasks
针对于该数据集，共有5个任务：（具体实例见上图）
1. **Personalization  Task  1:  Issuing  API  calls**  Users  make  a  query  containing  from  0  to  4  of  the required  fields  (sampled  uniformly).  The  bot  must  ask  questions  to  fill  the  missing  fields  and  then generate  the  proper  API  call.
2. **Personalization  Task  2:  Updating  API  calls**  Starting  by  issuing  an  API  call  as  in  Task  1,  users update  their  requests  between  1  and  4  times  (sampled  uniformly).  The  fields  to  update  are  selected randomly  and  the  bot  must  then  issue  the  updated  API  call.
3. **Personalization  Task  3:  Displaying  Options**  Given  a  user  request,  the  KB  is  queried  by  the corresponding  API  call  and  the  resulting  facts  are  added  to  the  dialog  history.  The  bot  must  sort  the restaurants  in  the  facts  using  simple  heuristics  (described  in  Section  3.3)  based  on  the  user’s  attributes and  propose  a  restaurant  to  the  users  until  they  accept.  Users  accept  a  suggestion  25%  of  the  time  or always  if  it  is  the  last  remaining  one.
4. **Personalization  Task  4:  Providing  extra  information**  Given  a  user  request  for  a  randomly  sampled  restaurant,  all  KB  facts  related  to  the  restaurant  are  added  to  the  history  and  the  dialog  is conducted  as  if  the  user  has  decided  to  book  a  table  there.  The  user  then  asks  for  the  directions  to  the restaurant,  its  contact  information  or  both  (with  probabilities  25%,  25%  and  50%  respectively).  The bot  must  learn  to  retrieve  the  correct  KB  facts  from  history,  tailored  for  the  user.  
	* direction: `{"cheap": "address and public_transport", "moderate or expensive": "address and parking"} ` 根据用户选择的餐厅price来选择，而非profile attribute
	* contact:  `{"young": "social_media", "middle-aged or elderly": "phone"}`
5. **Personalization  Task  5:  Conducting  full  dialogs**  Conversations  generated  for  task  5  combine  all  the  aspects  of  tasks  1-4  into  full  dialogs.

## Related Work

### 1. [A  Persona-Based  Neural  Conversation  Model](https://drive.google.com/open?id=1m-8zAXyZSuLetHXsVgVSsrSBbvoEAQ0z)
*Note:作者是李即为和高见枫*
简介：本文的模型其实很简单，核心思想就是学习不同说话者的分布式表征，然后利用这些表征来生成回复，主要适用于chit-chat领域。作者提出了两个模型**Speaker  Model**和**Speaker-Addressee  Model**。

**Speaker  Model**：

![Figure  1:  Illustrative  example  of  the  Speaker  Model  introduced  in  this  work.  Speaker  IDs  close  in  embedding  space  tend  to respond  in  the  same  manner.  These  speaker  embeddings  are  learned  jointly  with  word  embeddings  and  all  other  parameters  of the  neural  model  via  backpropagation.  In  this  example,  say  Rob  is  a  speaker  clustered  with  people  who  often  mention  England in  the  training  data,  then  the  generation  of  the  token  ‘england’  at  time  t  =  2  would  be  much  more  likely  than  that  of  ‘u.s.’.  A non-persona  model  would  prefer  generating  in  the  u.s.  if  ‘u.s.’  is  more  represented  in  the  training  data  across  all  speakers.](http://imglf5.nosdn0.126.net/img/bG1jbzEvdHVjVjJUdWs5YkJVMnRhUi96T0RKUis3V1l1a3BMVDcwODM1MU1FU2NwSnJuQUdBPT0.png?imageView&thumbnail=500x0&quality=96&stripmeta=0)

上图是一个传统的Seq2Seq模型，唯一不同点在于添加了speaker-specific embedding（注：原文里提到作者是通过年龄、居住地等信息判断是不是属于同一类speaker，并没有特别的标注数据：也即如果两个说话者的年龄等信息一致，认为是同一个Speaker，共享同一embedding），公式如下：

![](http://imglf3.nosdn0.126.net/img/bG1jbzEvdHVjVjJUdWs5YkJVMnRhZGtucHJwV05ML0Era3BqdndYUWkvTFZibnJVTCthNGNRPT0.png?imageView&thumbnail=500x0&quality=96&stripmeta=0)
(4)式代表四个等式：$i_{t} = \sigma(W_{1}e_{t}^{s}+W_{2}h_{t-1}+W_{3}v_{i})$ 其余同理，只是增加了$v_{i}$项，$e_{t}^{s}$代表word embedding。

**Speaker-Addressee  Model**：
这个模型的思想很直接，Speaker的回复风格除了取决于Speaker自身，还受Addressee(听众)的影响，因此要考虑两者的交互。

$$V_{i,j}=tanh(W_{i}\cdot v_{i}+W_{2}\cdot v_{j})$$

$v_{i}$ , $v_{j}$ 分别代表两个说话者。

![此时，用$V_{i,j}$代替v_{i}](http://imglf4.nosdn0.126.net/img/bG1jbzEvdHVjVjJUdWs5YkJVMnRhUzhoQkd4amIvTE55V0MxS3hoWVZHMWlSdFhnV0s4QjRnPT0.png?imageView&thumbnail=500x0&quality=96&stripmeta=0)

总结：这篇文章研究的是chit-chat领域的个性化问题，所以侧重点跟**Learning Personalized End-to-End Goal-Oriented Dialog**有所不同，本文实际上是对agent自身建模，解决的是回复一致性问题，但思路很简洁，还是可以借鉴。

> Instead  of  assigning  personality  to  agents  (Li  et  al.  2016;Luan  et  al.  2017;  Qian  et  al.  2017),  our  model  pays  more attention  to  the  user  persona  and  aims  to  make  agents  more adaptive  to  different  kinds  of  interlocutors. （from **Learning Personalized End-to-End Goal-Oriented Dialog**）

### 2. [Assigning  Personality/Identity  to  a  Chatting  Machine for  Coherent  Conversation  Generation](https://drive.google.com/open?id=12EzxUkUftvGPRWOawuFqSIHHN4nAeJXR)
*Note:清华的黄名列*

两个贡献点：
1. 相比于之前的工作（如Li），本文直接赋予chatbot一个显式的Identity，而不是隐式地从对话数据中学习；
2. 本文提出了一个全新的模型，包括`profile detector` `position detector` `bidirectional decoder`三个模块。

模型结构：

![Figure  1:  The  overall  process](http://imglf5.nosdn0.126.net/img/bG1jbzEvdHVjVjBOelBuN1dDd09vem45VW5wK2FFN1I2eVljOGc5VjNoZmdDVEVmWC9SNDBRPT0.png?imageView&thumbnail=500x0&quality=96&stripmeta=0)

模型执行流程（for test）：给定一个post，**profile detector**首先预测是否使用**agent profile**，如果不使用则直接使用传统的seq2seq解码器生成回复（对应上图中的forward decoder）；否则，`profile detector` 会选择一对合适的`profile key and value` 。以选出的`profile value`作为起点，`bidirectional decoder` 从前向和后向生成最终的回复。

**Encoder**：
单向GRU获取post的embedding表征，简单的将所有的word对应的$h_{t}$相加作为最终的表征：$\widetilde{h}=\sum_{j}h_{j}$

**Profile  Detector**：
该模块有两个功能：
1. 检测输入的post是否需要使用agent profile来回复
2. 选择特定的profile <key,value>传递给解码器

针对于功能一，作者构建了一个二分类器：
![](http://imglf4.nosdn0.126.net/img/bG1jbzEvdHVjVjBOelBuN1dDd09vMnJ5Q1AxcDMxMEtaZXZXQzZZT0dhTEdhaG5aSHJySUhnPT0.png?imageView&thumbnail=500x0&quality=96&stripmeta=0)
$z \in {0, 1}$，$z=1$ 代表使用agent profile。

针对于功能二，作者构建了一个MLP多分类器
![](http://imglf5.nosdn0.126.net/img/bG1jbzEvdHVjVjBOelBuN1dDd09vMVpmYm9XbHR5cUI4alNpTUdjOVRFa3dCWi9iZ1RqT2hnPT0.png?imageView&thumbnail=500x0&quality=96&stripmeta=0)
$k_{i},v_{i}$ 分别对应一个profile key and value，这些都是模型训练参数，f是softmax函数。选择概率最大的那一组 key－value。

**Bidirectional  Decoder**：
设定生成的回复为$y=(\mathbf{y^{b}},\widetilde{v},\mathbf{y^{f}})=(y_{1}^{b},...,y_{t-1}^{b},\widetilde{v},y_{t+1}^{f},...,y_{m}^{f})$，$\widetilde{v}$ 是选择的profile value。**Bidirectional  Decoder**首先基于$\widetilde{v}$为起点，反向生成$\mathbf{y^{b}}$；然后以$\mathbf{y^{b}}, \widetilde{v}$ 作为输入，前向生成回复的后半部分$\mathbf{y^{f}}$。
*details in original paper*

**Position  Detector**：（仅在训练阶段使用）

![The  training  process  of  the  model.  Given a  pair  <  x;y  >,  the  position  detector  will  predict a  position  小提琴-4(violin)  at  which  the  profile value  钢琴(piano)  can  be  replaced,  and  the  position  will  be  used  to  train  the  bidirectional  decoder.](http://imglf5.nosdn0.126.net/img/bG1jbzEvdHVjVjM0bUk0MGs4YW01K0tGRXptNUltcDl3SVlabkpKR1IzNmZXT3EwUXBxY053PT0.png?imageView&thumbnail=500x0&quality=96&stripmeta=0)

> As  mentioned,  the  bidirectional  decoder  starts  from  a  profile  value  to  generate  the  entire  sequence  at  the  test
stage.  However,  in  our  training  dataset,  the  profile values  may  be  rarely  mentioned  in  the  responses. For  instance,  given  the  profile  key  value  pair  <爱好,  冰球>  (<  hobby;hockey  >),  the  value  冰球(hockey)  rarely  occurs  in  the  training  corpus.  In other  words,  even  though  we  have  a  training  instance  (x;y;<  k;v  >),  the  value  (v)  may  not  occur  in  y  at  all.

**Position  Detector**的主要作用是解决模型训练和测试时的偏差问题：在训练时，很多训练样本中回复并没有包含profile value完全相同的词，例如上图中的例子，也即无法提供给bidirectional  decoder模块预测的起点；而在测试时，bidirectional  decoder模块一定会有预测的起点（因为profile detector是一个分类器，一定会有一个结果）。

> The  position  detector  is  designed  to  provide  a start  decoding  position  to  the  decoder  during  training.  For  instance,  given  a  post  x  =“你-1  有-2 什么-3  特长-4  ？-5  (what’s  your  speciality?)” and  a  response  y  =“我-1  非常-2  擅长-3  小提琴-4(I  am  good  at  playing  violin)”,  and  a  profile  key value  pair  “<特长,  钢琴>  (<hobby;piano>)”, the position  detector  will  predict  that  “小提琴-4(violin)”  in  the  response  can  be  replaced  by  the profile  value  “钢琴(piano)”  to  ensure  grammaticality.  The  predicted  position  “小提琴-4  (violin)” is  then  passed  to  the  decoder  (see  Eq.  6)  to  signal the  start  decoding  position.

作者简单地使用profile value和response word计算余弦相似度。

总结：本文主要创新点在于提出了agent profile，与Li的方法不同的是，本文作者并没有直接从对话中去学习个性化，而是直接给chatbot agent赋予profile，进而生成更加一致性且相关的对话。

*funny note：作者在论文最后提到了两处改进方向，一是对话方式，针对于不同的用户采取不同的说话方式（[Learning Personalized End-to-End Goal-Oriented Dialog](https://drive.google.com/open?id=1jRjiu4gd1k2UJ51_HLmP0hImjAs1Dk3X)正是基于该想法）*；二是在对话中融合常识推理（[Commonsense Knowledge Aware Conversation Generation with Graph Attention](https://drive.google.com/open?id=1mD17UBEZfDPJZYwlMmMZtIFqB71aD6Jy)）。

### 3.  [Content-Oriented  User  Modeling  for  Personalized Response  Ranking  in  Chatbots](https://drive.google.com/open?id=1645oisMgj5m2soTtFbd0LbUA6te-UwdM)

本文主要提出了两个模型，分别对应解决两个问题：

1. **Modeling  User  Based  on  User  Generated  Contents**：该模型主要是从只包含用户的post（非对话）中学习用户个性化表征。
2. **Personalized  Conversation  Modeling**：如何在匹配输入post和候选回复过程中利用用户个性化表征。

**Modeling  User  Based  on  User  Generated  Contents**：

![Fig.  1.  User  modeling  architecture](http://imglf3.nosdn0.126.net/img/bG1jbzEvdHVjVjJtTXlVcDhJeEJIaUprdHg5bERMV1YyTlB6bVJmaFljaG5TREtGU3B5TTRBPT0.png?imageView&thumbnail=500x0&quality=96&stripmeta=0)

Sentence Embedding是一个预训练好的语言模型，在user modeling过程中是固定的。User Embedding是一个随机初始化的embedding matrix，每一行vector对应一个用户的个性。整体上是一个FC：

![](http://imglf6.nosdn0.126.net/img/bG1jbzEvdHVjVjJtTXlVcDhJeEJIcFdQWHZuaWZGRVgzVXJpUzdsYk9OTEtMTWRhdm95RWZRPT0.png?imageView&thumbnail=500x0&quality=96&stripmeta=0)

其中：$u_{i,v}, p_{i, v}$ 分别代表user profile embedding和post embedding。模型最后的输出结果是个二分类{0, 1}，代表post和user是否对应。作者采用交叉熵损失函数：

![](http://imglf6.nosdn0.126.net/img/bG1jbzEvdHVjVjJtTXlVcDhJeEJIb3ZhRGJKKzFpSkRydHYzMXNQNGJabWsxeG1NKzU2eHJBPT0.png?imageView&thumbnail=500x0&quality=96&stripmeta=0)

**Personalized  Conversation  Modeling**: 核心思想很简单，将post embedding,user profile,candidate response分别拼接输入到FC中，如下所示，最终得到relevance score。

![Fig.  2.  Personalized  conversation  modeling  architecture  for  response  ranking](http://imglf3.nosdn0.126.net/img/bG1jbzEvdHVjVjJ0dUpxbkxxNGI3TlVRc2dKM1o3VVkrQnVLTmVhcVA2OW9lTDVtcGVmUmF3PT0.png?imageView&thumbnail=500x0&quality=96&stripmeta=0)

### 4. [Personalization in Goal-oriented Dialog](https://drive.google.com/open?id=1EcpoZFejVpRdfz6R289-SflhDG2siOvY)
*这篇文章实际上是提出了数据集，并建立了以下的baseline model*

![Figure 2: Split memory architecture for Memory Networks. Profile attributes and conversation history are modeled in two separate memories. The outputs from both memories are summed to get the final response.](http://imglf4.nosdn0.126.net/img/bG1jbzEvdHVjVjNLZFE1ME8xNW51TlBOWlpCY2s5YWFXNDBqempNQ2grUXNLazMrY0pQNG1RPT0.png?imageView&thumbnail=500x0&quality=96&stripmeta=0)

### 5. [Learning Personas from Dialogue with Attentive Memory Networks](https://drive.google.com/open?id=1LeBk6jOET9SkO-KSwCVV4D-nOMbCFzfF)
* EMNLP2018
* link: https://pralav.github.io/emnlp_personas/
* 这篇文章的出发点很独特，论文旨在从对话片段中预测用户个性。具体来讲，论文把不同的电影角色作为个性类别，然后从给定的电影对话片段中预测用户属于哪个角色类别。

（个性）角色类别示例：每一个character trope相当于一类个性
![Table  1:  Example  tropes  and  characters](http://imglf5.nosdn0.126.net/img/bG1jbzEvdHVjVjIwM1hhbWxaeEk4eElRVGlWUlZFRWdBbGc1Z01mR0FuSHVmWTZDTitPR2RRPT0.png?imageView&thumbnail=1680x0&quality=96&stripmeta=0)

IMDB电影对话数据集：对话包括三部分，角色的话，角色以外的话，以及附加上下文场景信息（图中斜体字）
![Figure  2:  Example  IMDB  dialogue  snippet  containing  multiple  characters  and  context.](http://imglf4.nosdn0.126.net/img/bG1jbzEvdHVjVjIwM1hhbWxaeEk4dzljQVdENm5sMWtWS3IvTGVhTGhEL3N1YVB3QnRmaTd3PT0.png?imageView&thumbnail=1680x0&quality=96&stripmeta=0)

除此之外，作者还建立了一个Character  Trope  Description  Dataset数据集，给每一类角色增加了角色描述信息。

Problem  Formulation：给定$N_{p}$类角色，每一类角色都包含大量的对话片段 $S=(D,E,O)$，D代表这个角色自身的话 $D=\left[w_{D_{1}}, w_{D_{2} \cdots,} w_{D_{T}}\right]$，E代表附加上下文场景信息 $E=\left[w_{E_{1}}, w_{E_{2} \cdots,} w_{E_{T}}\right]$，O代表其它角色的话 $O=\left[w_{O_{1}}, w_{O_{2} \cdots,} w_{O_{T}}\right]$ ，目的是根据对话片段S来预测D所属的角色类型，也即个性。（如果考虑Character  Trope  Description  Dataset，则还有角色描述信息）

模型结构：
![](http://imglf5.nosdn0.126.net/img/bG1jbzEvdHVjVjIwM1hhbWxaeEk4MFRMTUFzN1YwM3hTdXhhdDVRclBDdVE5TWtMNGZSd25nPT0.png?imageView&thumbnail=1680x0&quality=96&stripmeta=0)

模型主要分为两部分：

* 自注意力编码器：注意力编码器分为snippet内和snippet间两个level。snippet内是指D、E、O内token之间做self-attention分别得到向量表征 $D^{e},E^{e},O^{e}$；得到一个snippet的表征之后，再使用相同的自注意力机制对多个snippet的表示做运算，最后把D、E、O三者结合
	![](http://imglf6.nosdn0.126.net/img/bG1jbzEvdHVjVjIwM1hhbWxaeEk4MHZkdzdYbkNlTUlKNGt1ZHRUNTRWUzA5ZTNnODBOWlZRPT0.png?imageView&thumbnail=1680x0&quality=96&stripmeta=0)

* 记忆网络：以Knowledge-Store  Memory为例，memory key存储的是角色描述信息，memory value存储的是角色类别信息（每一类角色对应一个分布式向量）。使用自注意力编码器得到的z进行多跳注意力计算，之后就可以预测角色类别。

**Idea : 可以借助profile embedding做分类，验证profile model的有效性**
## Future Plans

### Profile Model
 - 对于profile embedding，作者使用了one-hot的编码方式，这点可以参考A  Persona-Based  Neural  Conversation  Model的隐性分布式表征和Assigning  Personality/Identity  to  a  Chatting  Machine for  Coherent  Conversation  Generation显示表征，把二者相结合。

 - profile embedding如何添加到dialog history encoding中，这涉及到两种策略：
	1. 修改memory network（需要看一下DSTC7关于sentence selection的论文，找一找有没有比memory network更好的结构，之后在新结构的基础上考虑添加profile embedding）；
		 * 序列架构：ESIM  每次计算交叉注意力的时候可以把profile embedding加进去
		 * 分层架构：DAM

	2. 在memory network不变的基础上，修改添加的方式
	3. profile embedding是静态添加的，即N hops时每次添加都是相同的，这点可以优化成动态变化的
	4. 本文是将对话回复当作一个分类问题，其实[Mem2Seq: Effectively Incorporating Knowledge Bases into End-to-End Task-Oriented Dialog Systems](http://link.zhihu.com/?target=http%3A//cn.arxiv.org/pdf/1804.08217v3)提供了一种新的方式，使用memory network来生成回复。（这实际上对应对话选择和对话生成两种问题）*这个难度有些大，但是有代码。如果当作生成问题，是不是可以把一些风格相关的词用指针网络来生成*   
		* 检索和生成两种模式可以组合：[Retrieve and Refine: Improved Sequence Generation Models For Dialogue](https://arxiv.org/abs/1808.04776v2)
 - 论文只使用了user profile ，并没有考虑agent，A  Persona-Based  Neural  Conversation  Model提到了一种简单直接地同时对对话的双方同时建模的方法，这种思想可以继承过来，但具体的交互方式要有所创新。

### Preference Model

这个模型的本质是给最终的候选回复添加一个偏置项$b_{i}$：

![enter image description here](http://imglf6.nosdn0.126.net/img/bG1jbzEvdHVjVjA2SUhtZ1hBSU15d29ld1NxZk5MSEY2c3dyQ252MnNyVGJ2Nko0cXAyNGN3PT0.png?imageView&thumbnail=500x0&quality=96&stripmeta=0)

这个偏置项的选择分为三种情况：
* 如果$b_{i}$对应的这个候选回复不包含任何的实体，则$b_{i}=0$
* 如果$b_{i}$对应的这个候选回复包含一个实体（作者设定一个候选项至多有一个实体），但是这个实体所对应的餐厅名在之前的对话中并没有出现， 则$b_{i}=0$
*  如果$b_{i}$对应的这个候选回复包含一个实体（作者设定一个候选项至多有一个实体），并且这个实体所对应的餐厅名在之前的对话中出现过， 则$b_{i}=v_{j}$ （$v_{j}$代表用户对于实体j的偏好分数，由用户profile计算得到）

第三种情况实际上才是真正的语义消歧过程，用户偏好会影响对实体的选择。（这点应该可以适用于NLU，不同的主题、领域会影响实体的识别）

**关于这个模型暂时没有什么想法**


## Paper

### 1. ESIM-enhanced model

![ESIM](http://imglf6.nosdn0.126.net/img/bG1jbzEvdHVjVjFmcCtkeExEbnJGRFpTQkRaQTIvRGY1cEtudW16WEpVSmlFOEE5NllNUWRBPT0.png?imageView&thumbnail=500x0&quality=96&stripmeta=0)

将原文中的memory network 替换成ESIM，计算local matching vectors时增加profile embedding，为了避免计算量太大，可以先使用BM25检索出前100个候选项。

 - [x] 参照[An Affect-Rich Neural Conversational Model with Biased Attention and Weighted Cross-Entropy Loss ](https://goo.gl/ByFsgh) 动态交互profile embedding（暂时不考虑）
 - [ ] 参照[DRr-Net: Dynamic Re-read Network for Sentence Semantic Matching](https://goo.gl/xNQayZ)，计算交叉注意力可以多次


### 2. Profile Embedding
原文中profile embedding使用one-hot编码再线性变换，可以修改为如下方式：

1. 分布式表征：定义一个embedding matrix $E \in R^{N \times d}$，矩阵的每一行为一种profile embedding；如果单独考虑同一种属性取值的关系，可以为每一种属性定义一个embedding matrix，每一行代表这个属性的不同取值，再把所有属性对应的embedding拼接起来

2. 显式表征：参照*Assigning  Personality/Identity  to  a  Chatting  Machine for  Coherent  Conversation  Generation*，可以使用注意力机制，分别学习profile key/value的表征，然后对所有的profile key/value计算注意力得到attentive profile embedding。直观理解来说，针对不同的上下文，所关注的user profile的属性也不同，因此user profile不同属性的重要程度是不一样的，例如对一个回复来说，用户的年龄属性比性别属性更重要，注意力的意义在于使得模型可以更加关注profile的某一方面，粒度更细。

3. 二者结合

### 3. Preference Model
基本思路不变，只是将候选项偏置添加到ESIM MLP的sigmoid函数

## Experiments

### Task 1: Issuing API calls
|      Setting          |Date                          |ACC                         |
|----------------|-------------------------------|-----------------------------|
|数据处理设置/home1/hkq2018/pythonProject/personalized_dialog/task1<br>/preprocessed_data/dataset_preprocessing.json<br>模型设置"/home1/hkq2018/pythonProject/personalized_dialog/task1<br>/personalized_dataset_training.json"|2019/4/26            |100.0000%            |
设置同上 | 2019/5/3 | 100.0000% 
 
1. task1实验结果有问题，大部分匹配错误是因为数字的原因。 => 原因：负采样使用一个batch里的其他样本，导致很难有数字差异而其它slot值相同的情况；修改为随机从300个api_call candidate中选取128个样本作为负样本，保证所有情况都有负样本。
2. task2使用task1预训练权重，否则没法收敛

task3有四个属性：
gender: {'female', 'male'}
age: {'elderly', 'young', 'middle-aged'}
type: {'non-veg', 'veg'}
speciality: {'tikka', 'fish_and_chips', 'biryani', 'tart', 'risotto', 'ratatouille', 'english_breakfast', 'paella', 'souffle', 'pasta', 'pizza', 'omlette', 'shepherds_pie', 'curry', 'tapas'}

